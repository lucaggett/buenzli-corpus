{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-05T00:51:35.153858Z",
     "start_time": "2023-07-05T00:51:35.150731Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki.xml\n",
      "schobinger.xml\n",
      "blick.xml\n",
      "swatch.xml\n",
      "blogs.xml\n"
     ]
    }
   ],
   "source": [
    "# get all files in path\n",
    "files = (file for file in os.listdir(\"../NOAH-Corpus\") if file.endswith(\".xml\"))\n",
    "# create dictionary for words and their frequencies\n",
    "words = {}\n",
    "\n",
    "# iterate through files\n",
    "for file in files:\n",
    "    # parse xml file\n",
    "    print(file)\n",
    "    tree = ET.parse(open(\"../NOAH-Corpus/\" + file, \"r\", encoding=\"utf-8\"))\n",
    "    # get root element\n",
    "    root = tree.getroot()\n",
    "    # iterate through all text elements\n",
    "    for article in root.iter(\"document\"):\n",
    "        for sent in article.iter(\"s\"):\n",
    "            for word_element in sent.iter(\"w\"):\n",
    "                # get word\n",
    "                word = word_element.text\n",
    "                word = word.lower()\n",
    "                # if word is not in dictionary, add it\n",
    "                if word not in words:\n",
    "                    words[word] = 1\n",
    "                # else increment frequency\n",
    "                else:\n",
    "                    words[word] += 1\n",
    "\n",
    "\n",
    "sorted(words.items(), key=lambda x: x[1], reverse=True)\n",
    "NOAH_frequencies = copy(words)\n",
    "del words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T00:58:05.827422Z",
     "start_time": "2023-07-05T00:58:05.525304Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.176436154773465\n",
      "[('und', 21197), ('isch', 18917), ('de', 17210), ('das', 15846), ('es', 11269), ('die', 10940), ('aber', 10045), ('ich', 9433), ('i', 9038), ('au', 8884), ('so', 8701), ('wo', 8695), ('d', 7945), ('vo', 7800), ('', 7623), ('mit', 7364), ('en', 6580), ('du', 6410), ('dass', 5948), ('für', 5931), ('e', 5922), ('nid', 5753), ('im', 5519), ('uf', 5517), ('nöd', 5400), ('mer', 5350), ('no', 5232), ('was', 5061), ('wie', 5059), ('ja', 5011), ('in', 4870), ('oder', 4848), ('ned', 4623), ('scho', 4609), ('als', 4416), ('sind', 4243), ('wenn', 4241), ('bi', 3887), ('z', 3862), ('s', 3830), ('eifach', 3790), ('da', 3780), ('het', 3743), ('sich', 3694), ('nur', 3492), ('denn', 3428), ('mir', 3310), ('zum', 3225), ('am', 3186), ('si', 3165), ('der', 3107), ('sie', 3043), ('dr', 2892), ('ha', 2859), ('a', 2783), ('di', 2619), ('kei', 2505), ('mal', 2500), ('me', 2448), ('immer', 2393), ('zu', 2319), ('meh', 2297), ('dem', 2253), ('doch', 2206), ('dä', 2154), ('vom', 2135), ('er', 2117), ('wird', 2020), ('han', 2017), ('us', 1968), ('jetzt', 1921), ('grad', 1858), ('halt', 1836), ('lüt', 1811), ('ganz', 1801), ('esch', 1777), ('-', 1766), ('hesch', 1762), ('vor', 1754), ('mi', 1709), ('hend', 1682), ('will', 1671), ('jo', 1649), ('über', 1581), ('also', 1534), ('ond', 1496), ('guet', 1495), ('the', 1482), ('cha', 1475), ('u', 1472), ('ds', 1434), ('um', 1426), ('chli', 1413), ('alli', 1405), ('bin', 1390), ('hani', 1384), ('em', 1383), ('alles', 1373), ('wär', 1347), ('do', 1337)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from copy import copy\n",
    "with open(\"../buenzli-corpus/comments.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    comments = json.load(f)\n",
    "\n",
    "word_frequencies = {}\n",
    "for comment in comments:\n",
    "    sentence = comment[\"body\"]\n",
    "    for word in sentence.split(\" \"):\n",
    "        word = word.lower()\n",
    "        if word not in word_frequencies:\n",
    "            word_frequencies[word] = 1\n",
    "        else:\n",
    "            word_frequencies[word] += 1\n",
    "\n",
    "total_words = sum(word_frequencies.values())\n",
    "\n",
    "average_word_length = sum(len(word) * freq for word, freq in word_frequencies.items()) / total_words\n",
    "\n",
    "print(average_word_length, sep=\"\\n\")\n",
    "\n",
    "\n",
    "print(sorted(word_frequencies.items(), key=lambda x: x[1], reverse=True)[:100])\n",
    "\n",
    "buenzli_frequencies = copy(word_frequencies)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T00:58:09.646449Z",
     "start_time": "2023-07-05T00:58:09.282584Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176634\n",
      "12522\n",
      "['', 'interessanter,', '\"krise\"', 'gernüd', 'buenzli.\\n\\ni', 'market.', 'schad,', 'werbige.', 'top-empfälige', 'a.a.', 'überarbeitet](https://imgur.com/a/58ukxlk)', 'ziiitstempel', 'afrikanischi', 'basel&gt;züri\\nbip', 'heillig', 'bünzli-bueb', 'dhreit', \"z'züri.\", 'sälbstüberschetzig.', 'dörfsch', 'ernscht,', 'abstimmigsbüechli.', '\"ad', 'motorisch', 'öschterriichische', 'grösteteils', 'unterschreibe', 'ufgfalle,', 'ok\\n\\nakunft', 'atöpplend', 'wärded.', 'kriege', 'besta.', 'zeichnet,', 'denn..', 'immobilienverwaltungen', 'broschürli', 'discus', 'zschtelle,', 'schuldpapier', 'nachforschig', 'regions.', 'spion!\\npour', 'erwähnenswerti', 'chratzts,', 'jahren:\\n\\n\"hört', 'under-hasgläse', 'soviil,', '\"assigned', 'ztue?\\n\\nwills', 'gshrumpft.', '**züri**.', 'teilt?', 'schlimmstefalls', 'extrahiere?', 'spanne', 'sprach(l2),', 'dtum', 'taxi\\n\\nweisch,', 'botzduusignomolle', 'holä.', 'selbschdverständlech', 'mist\"', 'hiuf?\\ndere', 'wünsche,', 'weltgschehe', 'mirror](https://i.imgur.com/tspklfu.jpg)\\n\\n', 'selber.\\naber', '1.6%.', 'johrhudert', 'plagööri,', 'gseit\\n\\nobwohl', 'dräckig,', 'regierungsratpräsi,', 'uffülle', 'co2-emissione', 'stadtparlament', 'füregno', 'wet)', 'schweizerlöhnen', 'lobbyste', 'niä“\\n\\nglaub', 'erinnered.', 'sensationsmedie', '10vor10', 'schötzid', 'preposterous.', 'richtet,', 'stümmt', 'schnuret', 'familie.', 'chrüzritter?', 'rassistischs', 'währendere', 'chälerchinder', 'scheum,', 'mii', 'agsicht', 's‘schwiizerchrüz', 'fiesisti']\n",
      "**************************************************************************************************** \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['bvb', 'agfrögt', 'notturna', 'wundersamerwiis', 'bùndesligaverain', 'predigerchile', 'stahlamband', 'dodervo', 'müesen', 'naechschte', 'ladina', 'nèè', 'saisonfinau', 'bodäinschtrument', 'ertragswachstum', 'filiala', 'aaggnèèm', 'baja', 'fantasy-literatuir', 'gröiel', 'färnsee', 'epos', 'urche', 'bedienerfründlichkeit', 'altersusflug', 'alber', 'konfessionelli', 'strängä', 'haifisch', 'konsolidiärt', 'anegelait', 'wäde', 'serpentineazeiger', 'verfassä', 'thürsch', 'pensionskassa', 'schtroos', 'erläsene', 'äinzelne', 'chronographa', 'liäbt', 'selektivi', 'aigeni', '395', 'laufstegtrends', 'sankt-pheeter', 'draigötterrelief', 'völkerrechtswüsseschaft', '104.47', 'mittlä', 'goldziffereblätter', 'aahzneeh', 'blancpain-botschaftor', 'stehled', 'serata', 'nettischte', 'produggziuu', 'galerii', 'lcd', 'boutique', 'geziiutä', 'umsi', 'ifiährigskampagnä', 'zugschtumme', 'strawberries', 'oschtschwyzerdütsch', 'seriä', 'verfassigsänderige', 'flächene', 'pùùrscht', 'strömige', 'gsunntiget', 'vertüüfe', 'queens', 'längschti', 'orion', 'igängige', 'zange', 'schmerzlich', 'öschtlech', 'bapiirchoorb', 'beschtehe', 'ochsebai', 'sämtlichä', 'fotografin', 'deepika', 'föumfestivals', 'ryychi', 'thursday', 'ghebt', 'nèrve', 'noochwuxturnier', 'people’', 'rollsigel', 'gfüahrt', 'chronographemechanismus', 'losdüsed', 'jungstaizytlichs', 'edelstahl-', 'fassigsvermögä']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Utility data structures\n",
    "\"\"\"\n",
    "\n",
    "buenzli_words = set(buenzli_frequencies.keys())\n",
    "NOAH_words = set(NOAH_frequencies.keys())\n",
    "\n",
    "words_not_in_NOAH = buenzli_words - NOAH_words\n",
    "words_not_in_buenzli = NOAH_words - buenzli_words\n",
    "\n",
    "normalized_NOAH_frequencies = {word: freq / len(NOAH_words) for word, freq in NOAH_frequencies.items()}\n",
    "normalized_buenzli_frequencies = {word: freq / len(buenzli_words) for word, freq in buenzli_frequencies.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T00:58:11.242744Z",
     "start_time": "2023-07-05T00:58:11.240903Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
